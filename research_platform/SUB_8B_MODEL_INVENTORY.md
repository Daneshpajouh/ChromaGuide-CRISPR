# Sub-8B Model Inventory
> **Focus**: Highly portable models ranging from sub-1B to 8B parameters.

## Ultra-Light (<1B Parameters)
| Model | Params | Disk | Arch | Version | Likes | Org | Tags |
|---|---|---|---|---|---|---|---|
| [stable-diffusion-3-medium](https://huggingface.co/stabilityai/stable-diffusion-3-medium) | Unknown | 34.4 GB | Unknown | N/A | 4878 | stabilityai | diffusion-single-file, text-to-image, stable-diffusion |
| [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) | 22.7M | 0.17 GB | bert | v2 | 4238 | sentence-transformers | sentence-transformers, pytorch, tf |
| [whisper-large-v3-turbo](https://huggingface.co/openai/whisper-large-v3-turbo) | 808.9M | 1.51 GB | whisper | v3 | 2728 | openai | transformers, safetensors, whisper |
| [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14) | 427.6M | 3.19 GB | clip | N/A | 1927 | openai | transformers, pytorch, tf |
| [RMBG-1.4](https://huggingface.co/briaai/RMBG-1.4) | 44.1M | 0.49 GB | SegformerForSemanticSegmentation | 1.4 | 1913 | briaai | transformers, pytorch, onnx |
| [Florence-2-large](https://huggingface.co/microsoft/Florence-2-large) | 776.7M | 2.9 GB | florence2 | arxiv:2311.06242 | 1721 | microsoft | transformers, pytorch, safetensors |
| [blip-image-captioning-large](https://huggingface.co/Salesforce/blip-image-captioning-large) | 469.7M | 3.5 GB | blip | arxiv:2201.12086 | 1439 | Salesforce | transformers, pytorch, tf |
| [PaddleOCR-VL](https://huggingface.co/PaddlePaddle/PaddleOCR-VL) | 958.6M | 1.79 GB | paddleocr_vl | ERNIE4.5 | 1411 | PaddlePaddle | PaddleOCR, safetensors, paddleocr_vl |
| [parakeet-tdt-0.6b-v2](https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2) | Unknown | Unknown | Unknown | 0.6 | 1386 | nvidia | nemo, automatic-speech-recognition, speech |
| [embeddinggemma-300m](https://huggingface.co/google/embeddinggemma-300m) | 302.9M | 1.13 GB | gemma3_text | arxiv:2509.20354 | 1337 | google | sentence-transformers, safetensors, gemma3_text |
| [bitnet-b1.58-2B-4T](https://huggingface.co/microsoft/bitnet-b1.58-2B-4T) | 849.8M | 1.1 GB | bitnet | 1.58 | 1229 | microsoft | transformers, safetensors, bitnet |
| [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) | 109.5M | 0.82 GB | mpnet | v2 | 1207 | sentence-transformers | sentence-transformers, pytorch, onnx |
| [jina-embeddings-v3](https://huggingface.co/jinaai/jina-embeddings-v3) | 572.3M | 2.13 GB | Unknown | v3 | 1111 | jinaai | transformers, pytorch, onnx |
| [paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) | 117.7M | 0.88 GB | bert | v2 | 1078 | sentence-transformers | sentence-transformers, pytorch, tf |
| [granite-docling-258M](https://huggingface.co/ibm-granite/granite-docling-258M) | 257.5M | 0.48 GB | idefics3 | arxiv:2501.17887 | 1055 | ibm-granite | transformers, safetensors, idefics3 |
| [flan-t5-base](https://huggingface.co/google/flan-t5-base) | 247.6M | 1.85 GB | t5 | N/A | 1029 | google | transformers, pytorch, tf |
| [RMBG-2.0](https://huggingface.co/briaai/RMBG-2.0) | 220.7M | 1.65 GB | Unknown | 2.0 | 973 | briaai | transformers, pytorch, onnx |
| [gemma-3-270m](https://huggingface.co/google/gemma-3-270m) | 268.1M | 0.5 GB | gemma3_text | N/A | 931 | google | transformers, safetensors, gemma3_text |
| [vit-base-patch16-224](https://huggingface.co/google/vit-base-patch16-224) | 86.6M | 0.65 GB | vit | N/A | 912 | google | transformers, pytorch, tf |
| [Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B) | 751.6M | 1.4 GB | qwen3 | 0.6 | 889 | Qwen | transformers, safetensors, qwen3 |
| [stable-diffusion-3.5-medium](https://huggingface.co/stabilityai/stable-diffusion-3.5-medium) | Unknown | 4.76 GB | Unknown | 3.5 | 872 | stabilityai | diffusers, safetensors, text-to-image |
| [flan-t5-large](https://huggingface.co/google/flan-t5-large) | 783.2M | 5.84 GB | t5 | N/A | 855 | google | transformers, pytorch, tf |
| [bge-reranker-v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3) | 567.8M | 2.12 GB | xlm-roberta | v2 | 833 | BAAI | sentence-transformers, safetensors, xlm-roberta |
| [Qwen3-Embedding-0.6B](https://huggingface.co/Qwen/Qwen3-Embedding-0.6B) | 595.8M | 1.11 GB | qwen3 | 0.6 | 788 | Qwen | sentence-transformers, safetensors, qwen3 |
| [VoxCPM-0.5B](https://huggingface.co/openbmb/VoxCPM-0.5B) | 0.5B | 1.5 GB | Unknown | 0.5 | 777 | openbmb | voxcpm, pytorch, text-to-speech |
| [timesfm-1.0-200m](https://huggingface.co/google/timesfm-1.0-200m) | Unknown | Unknown | Unknown | 1.0 | 777 | google | timesfm, time-series-forecasting, arxiv:2310.10688 |
| [gemma-3-1b-it](https://huggingface.co/google/gemma-3-1b-it) | 999.9M | 1.87 GB | gemma3_text | arxiv:1905.07830 | 750 | google | transformers, safetensors, gemma3_text |
| [jina-embeddings-v2-base-en](https://huggingface.co/jinaai/jina-embeddings-v2-base-en) | 137.4M | 1.53 GB | bert | v2 | 731 | jinaai | sentence-transformers, pytorch, coreml |
| [siglip-so400m-patch14-384](https://huggingface.co/google/siglip-so400m-patch14-384) | 878.0M | 3.27 GB | siglip | N/A | 630 | google | transformers, safetensors, siglip |
| [bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5) | 335.1M | 2.5 GB | bert | v1.5 | 609 | BAAI | sentence-transformers, pytorch, onnx |
| [Phi-3-mini-4k-instruct-gguf](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf) | Unknown | 9.35 GB | Unknown | N/A | 548 | microsoft | gguf, nlp, code |
| [OmniVLM-968M](https://huggingface.co/NexaAI/OmniVLM-968M) | Unknown | 6.3 GB | Unknown | N/A | 527 | NexaAI | gguf, multimodal, conversational |
| [gemma-3-270m-it](https://huggingface.co/google/gemma-3-270m-it) | 268.1M | 0.5 GB | gemma3_text | N/A | 489 | google | transformers, safetensors, gemma3_text |
| [layoutlmv3-base](https://huggingface.co/microsoft/layoutlmv3-base) | 125.3M | 1.4 GB | layoutlmv3 | v3 | 465 | microsoft | transformers, pytorch, tf |
| [parakeet-tdt-0.6b-v3](https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3) | Unknown | Unknown | Unknown | 0.6 | 460 | nvidia | nemo, automatic-speech-recognition, speech |
| [stable-diffusion-3-medium-diffusers](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers) | Unknown | Unknown | Unknown | N/A | 427 | stabilityai | diffusers, safetensors, text-to-image |
| [Hunyuan3D-2mv](https://huggingface.co/tencent/Hunyuan3D-2mv) | Unknown | Unknown | Unknown | N/A | 395 | tencent | hunyuan3d-2, image-to-3d, text-to-3d |
| [FastVLM-0.5B](https://huggingface.co/apple/FastVLM-0.5B) | 758.8M | 1.41 GB | llava_qwen2 | 0.5 | 357 | apple | ml-fastvlm, safetensors, llava_qwen2 |
| [jina-reranker-v2-base-multilingual](https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual) | 278.4M | 1.04 GB | Unknown | v2 | 331 | jinaai | transformers, pytorch, onnx |
| [SmolVLM-256M-Instruct](https://huggingface.co/HuggingFaceTB/SmolVLM-256M-Instruct) | 256.5M | 0.48 GB | idefics3 | N/A | 312 | HuggingFaceTB | transformers, onnx, safetensors |
| [SmolLM2-135M-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct) | 134.5M | 0.25 GB | llama | N/A | 272 | HuggingFaceTB | transformers, tensorboard, onnx |
| [canary-1b-flash](https://huggingface.co/nvidia/canary-1b-flash) | 811.0M | 3.02 GB | fastconformer | N/A | 260 | nvidia | nemo, safetensors, fastconformer |
| [jina-embeddings-v2-base-zh](https://huggingface.co/jinaai/jina-embeddings-v2-base-zh) | 160.8M | 0.6 GB | bert | v2 | 245 | jinaai | sentence-transformers, pytorch, onnx |
| [SmolLM-135M](https://huggingface.co/HuggingFaceTB/SmolLM-135M) | 134.5M | 0.5 GB | llama | N/A | 238 | HuggingFaceTB | transformers, onnx, safetensors |

## Edge/Mobile (1B-3B Parameters)
| Model | Params | Disk | Arch | Version | Likes | Org | Tags |
|---|---|---|---|---|---|---|---|
| [whisper-large-v3](https://huggingface.co/openai/whisper-large-v3) | 1.5B | 17.25 GB | whisper | v3 | 5212 | openai | transformers, pytorch, jax |
| [phi-2](https://huggingface.co/microsoft/phi-2) | 2.8B | 5.18 GB | phi | N/A | 3412 | microsoft | transformers, safetensors, phi |
| [DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) | 3.3B | 6.21 GB | deepseek_vl_v2 | arxiv:2510.18234 | 2979 | deepseek-ai | transformers, safetensors, deepseek_vl_v2 |
| [Llama-3.2-1B](https://huggingface.co/meta-llama/Llama-3.2-1B) | 1.2B | 2.3 GB | llama | 3.2 | 2225 | meta-llama | transformers, safetensors, llama |
| [VibeVoice-1.5B](https://huggingface.co/microsoft/VibeVoice-1.5B) | 2.7B | 5.04 GB | vibevoice | 1.5 | 2099 | microsoft | transformers, safetensors, vibevoice |
| [Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct) | 3.2B | 5.98 GB | llama | 3.2 | 1877 | meta-llama | transformers, safetensors, llama |
| [whisper-large-v2](https://huggingface.co/openai/whisper-large-v2) | 1.5B | 11.5 GB | whisper | v2 | 1777 | openai | transformers, pytorch, tf |
| [DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) | 1.8B | 3.31 GB | qwen2 | 1.5 | 1410 | deepseek-ai | transformers, safetensors, qwen2 |
| [phi-1_5](https://huggingface.co/microsoft/phi-1_5) | 1.4B | 2.64 GB | phi | N/A | 1352 | microsoft | transformers, safetensors, phi |
| [gemma-2-2b-it](https://huggingface.co/google/gemma-2-2b-it) | 2.6B | 4.87 GB | gemma2 | N/A | 1247 | google | transformers, safetensors, gemma2 |
| [Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct) | 1.2B | 2.3 GB | llama | 3.2 | 1210 | meta-llama | transformers, safetensors, llama |
| [gemma-2b](https://huggingface.co/google/gemma-2b) | 2.5B | 14.01 GB | gemma | N/A | 1119 | google | transformers, safetensors, gguf |
| [VibeVoice-Realtime-0.5B](https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B) | 1.0B | 1.9 GB | vibevoice_streaming | 0.5 | 944 | microsoft | transformers, safetensors, vibevoice_streaming |
| [Octopus-v2](https://huggingface.co/NexaAI/Octopus-v2) | 2.5B | 4.67 GB | gemma | v2 | 891 | NexaAI | transformers, safetensors, gemma |
| [SmolLM3-3B](https://huggingface.co/HuggingFaceTB/SmolLM3-3B) | 3.1B | 5.73 GB | smollm3 | license:apache-2.0 | 842 | HuggingFaceTB | transformers, safetensors, smollm3 |
| [gemma-2b-it](https://huggingface.co/google/gemma-2b-it) | 2.5B | 14.01 GB | gemma | N/A | 827 | google | transformers, safetensors, gguf |
| [ReaderLM-v2](https://huggingface.co/jinaai/ReaderLM-v2) | 1.5B | 2.88 GB | qwen2 | v2 | 735 | jinaai | transformers, onnx, safetensors |
| [stable-fast-3d](https://huggingface.co/stabilityai/stable-fast-3d) | 1.0B | 3.75 GB | Unknown | N/A | 716 | stabilityai | safetensors, image-to-3d, dataset:allenai/objaverse |
| [SmolLM2-1.7B-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct) | 1.7B | 3.19 GB | llama | 1.7 | 690 | HuggingFaceTB | transformers, tensorboard, onnx |
| [Llama-3.2-3B](https://huggingface.co/meta-llama/Llama-3.2-3B) | 3.2B | 5.98 GB | llama | 3.2 | 675 | meta-llama | transformers, safetensors, llama |
| [stable-code-3b](https://huggingface.co/stabilityai/stable-code-3b) | 2.8B | 14.41 GB | stablelm | N/A | 658 | stabilityai | transformers, safetensors, gguf |
| [gemma-2-2b](https://huggingface.co/google/gemma-2-2b) | 2.6B | 9.74 GB | gemma2 | N/A | 613 | google | transformers, safetensors, gemma2 |
| [reader-lm-1.5b](https://huggingface.co/jinaai/reader-lm-1.5b) | 1.5B | 2.88 GB | qwen2 | 1.5 | 607 | jinaai | transformers, safetensors, qwen2 |
| [Hunyuan-1.8B-Instruct](https://huggingface.co/tencent/Hunyuan-1.8B-Instruct) | 1.8B | 3.34 GB | hunyuan_v1_dense | 1.8 | 597 | tencent | transformers, safetensors, hunyuan_v1_dense |
| [Janus-1.3B](https://huggingface.co/deepseek-ai/Janus-1.3B) | 2.1B | 3.89 GB | multi_modality | 1.3 | 592 | deepseek-ai | transformers, safetensors, multi_modality |
| [gemma-3n-E2B-it-litert-preview](https://huggingface.co/google/gemma-3n-E2B-it-litert-preview) | Unknown | Unknown | Unknown | N/A | 572 | google | image-text-to-text, arxiv:1905.07830, arxiv:1905.10044 |
| [MiniCPM-V-2](https://huggingface.co/openbmb/MiniCPM-V-2) | 3.4B | 6.4 GB | minicpmv | arxiv:2403.11703 | 482 | openbmb | transformers, safetensors, minicpmv |
| [Janus-Pro-1B](https://huggingface.co/deepseek-ai/Janus-Pro-1B) | Unknown | 3.89 GB | multi_modality | N/A | 465 | deepseek-ai | transformers, pytorch, multi_modality |
| [canary-1b](https://huggingface.co/nvidia/canary-1b) | Unknown | Unknown | Unknown | N/A | 452 | nvidia | nemo, automatic-speech-recognition, automatic-speech-translation |
| [Wan2.1-T2V-1.3B](https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B) | Unknown | 16.34 GB | t2v | 2.1 | 404 | Wan-AI | diffusers, safetensors, t2v |
| [deberta-v3-base](https://huggingface.co/microsoft/deberta-v3-base) | Unknown | 0.35 GB | deberta-v2 | v3 | 385 | microsoft | transformers, pytorch, tf |
| [CogVideoX-2b](https://huggingface.co/zai-org/CogVideoX-2b) | Unknown | Unknown | Unknown | N/A | 343 | zai-org | diffusers, safetensors, cogvideox |
| [GR00T-N1-2B](https://huggingface.co/nvidia/GR00T-N1-2B) | 2.2B | 4.08 GB | gr00t_n1 | N/A | 340 | nvidia | safetensors, gr00t_n1, robotics |
| [OpenELM-3B-Instruct](https://huggingface.co/apple/OpenELM-3B-Instruct) | 3.0B | 5.66 GB | openelm | N/A | 339 | apple | transformers, safetensors, openelm |
| [LFM2-1.2B](https://huggingface.co/LiquidAI/LFM2-1.2B) | 1.2B | 2.18 GB | lfm2 | 1.2 | 333 | LiquidAI | transformers, safetensors, lfm2 |
| [canary-qwen-2.5b](https://huggingface.co/nvidia/canary-qwen-2.5b) | 2.6B | 4.77 GB | Unknown | 2.5 | 326 | nvidia | nemo, safetensors, automatic-speech-recognition |
| [canary-1b-v2](https://huggingface.co/nvidia/canary-1b-v2) | Unknown | Unknown | Unknown | v2 | 320 | nvidia | nemo, automatic-speech-recognition, automatic-speech-translation |
| [LFM2-Audio-1.5B](https://huggingface.co/LiquidAI/LFM2-Audio-1.5B) | 1.5B | 3.1 GB | Unknown | 1.5 | 319 | LiquidAI | liquid-audio, safetensors, liquid |
| [stablelm-3b-4e1t](https://huggingface.co/stabilityai/stablelm-3b-4e1t) | 2.8B | 5.21 GB | stablelm | N/A | 312 | stabilityai | transformers, safetensors, stablelm |
| [MiniCPM-2B-sft-fp32](https://huggingface.co/openbmb/MiniCPM-2B-sft-fp32) | Unknown | 10.15 GB | Unknown | N/A | 296 | openbmb | transformers, pytorch, text-generation |
| [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b) | 3B | 5.29 GB | gpt_neox | v2 | 293 | databricks | transformers, pytorch, gpt_neox |
| [SmolVLM2-2.2B-Instruct](https://huggingface.co/HuggingFaceTB/SmolVLM2-2.2B-Instruct) | 2.2B | 8.37 GB | smolvlm | 2.2 | 291 | HuggingFaceTB | transformers, safetensors, smolvlm |
| [OmniAudio-2.6B](https://huggingface.co/NexaAI/OmniAudio-2.6B) | Unknown | 11.78 GB | Unknown | 2.6 | 282 | NexaAI | gguf, audio-text-to-text, chat |
| [btlm-3b-8k-base](https://huggingface.co/cerebras/btlm-3b-8k-base) | Unknown | 4.93 GB | btlm | N/A | 266 | cerebras | transformers, pytorch, btlm |
| [Hymba-1.5B-Instruct](https://huggingface.co/nvidia/Hymba-1.5B-Instruct) | 1.5B | 2.84 GB | hymba | 1.5 | 242 | nvidia | transformers, safetensors, hymba |
| [granite-4.0-micro](https://huggingface.co/ibm-granite/granite-4.0-micro) | 3.4B | 6.34 GB | granitemoehybrid | 4.0 | 240 | ibm-granite | transformers, safetensors, granitemoehybrid |
| [Nemotron-Research-Reasoning-Qwen-1.5B](https://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B) | 1.8B | 6.62 GB | qwen2 | 1.5 | 235 | nvidia | transformers, safetensors, qwen2 |

## Portable/Standard (3B-8B Parameters)
| Model | Params | Disk | Arch | Version | Likes | Org | Tags |
|---|---|---|---|---|---|---|---|
| [Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B) | 8.0B | 14.96 GB | llama | N/A | 6402 | meta-llama | transformers, safetensors, llama |
| [Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) | 8.0B | 14.96 GB | llama | 3.1 | 5144 | meta-llama | transformers, safetensors, llama |
| [Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) | 6.7B | 25.1 GB | llama | N/A | 4672 | meta-llama | transformers, pytorch, safetensors |
| [Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) | 46.7B | 177.4 GB | mixtral | v0.1 | 4620 | mistralai | vllm, safetensors, mixtral |
| [Llama-2-7b](https://huggingface.co/meta-llama/Llama-2-7b) | Unknown | 12.55 GB | llama | N/A | 4432 | meta-llama | facebook, meta, pytorch |
| [Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) | 8.0B | 14.96 GB | llama | N/A | 4327 | meta-llama | transformers, safetensors, llama |
| [Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1) | 7.2B | 27.47 GB | mistral | v0.1 | 4019 | mistralai | transformers, pytorch, safetensors |
| [Janus-Pro-7B](https://huggingface.co/deepseek-ai/Janus-Pro-7B) | Unknown | 13.82 GB | multi_modality | N/A | 3540 | deepseek-ai | transformers, pytorch, multi_modality |
| [gemma-7b](https://huggingface.co/google/gemma-7b) | 8.5B | 47.72 GB | gemma | arxiv:2305.14314 | 3245 | google | transformers, safetensors, gguf |
| [Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) | 7.2B | 27.47 GB | mistral | v0.2 | 3037 | mistralai | transformers, pytorch, safetensors |
| [chatglm-6b](https://huggingface.co/zai-org/chatglm-6b) | 6B | 12.5 GB | chatglm | arxiv:2103.10360 | 2867 | zai-org | transformers, pytorch, chatglm |
| [Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) | 7.2B | 27.0 GB | mistral | v0.3 | 2308 | mistralai | vllm, safetensors, mistral |
| [Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf) | 6.7B | 25.1 GB | llama | N/A | 2221 | meta-llama | transformers, pytorch, safetensors |
| [chatglm2-6b](https://huggingface.co/zai-org/chatglm2-6b) | Unknown | 11.63 GB | chatglm | N/A | 2056 | zai-org | transformers, pytorch, chatglm |
| [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B) | 8.0B | 14.96 GB | llama | 3.1 | 1976 | meta-llama | transformers, safetensors, llama |
| [Qwen2.5-Omni-7B](https://huggingface.co/Qwen/Qwen2.5-Omni-7B) | 10.7B | 20.83 GB | qwen2_5_omni | 2.5 | 1829 | Qwen | transformers, safetensors, qwen2_5_omni |
| [zephyr-7b-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) | 7.2B | 26.98 GB | mistral | arxiv:2305.18290 | 1816 | HuggingFaceH4 | transformers, pytorch, safetensors |
| [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) | 7.2B | 27.47 GB | mistral | v0.1 | 1816 | mistralai | transformers, pytorch, safetensors |
| [Mixtral-8x7B-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1) | 46.7B | 177.4 GB | mixtral | v0.1 | 1772 | mistralai | vllm, safetensors, mixtral |
| [Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct) | 3.8B | 7.12 GB | phi3 | N/A | 1685 | microsoft | transformers, safetensors, phi3 |
| [DeepSeek-V3-Base](https://huggingface.co/deepseek-ai/DeepSeek-V3-Base) | 684.5B | 641.3 GB | deepseek_v3 | V3 | 1681 | deepseek-ai | safetensors, deepseek_v3, custom_code |
| [Phi-4-multimodal-instruct](https://huggingface.co/microsoft/Phi-4-multimodal-instruct) | 5.6B | 10.38 GB | phi4mm | arxiv:2503.01743 | 1549 | microsoft | transformers, safetensors, phi4mm |
| [gemma-3n-E4B-it-litert-preview](https://huggingface.co/google/gemma-3n-E4B-it-litert-preview) | Unknown | Unknown | Unknown | N/A | 1479 | google | image-text-to-text, arxiv:1905.07830, arxiv:1905.10044 |
| [Qwen2.5-VL-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct) | 8.3B | 15.45 GB | qwen2_5_vl | 2.5 | 1396 | Qwen | transformers, safetensors, qwen2_5_vl |
| [Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) | 3.8B | 7.12 GB | phi3 | N/A | 1351 | microsoft | transformers, safetensors, phi3 |
| [Qwen2-VL-7B-Instruct](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct) | 8.3B | 15.44 GB | qwen2_vl | N/A | 1248 | Qwen | transformers, safetensors, qwen2_vl |
| [gemma-7b-it](https://huggingface.co/google/gemma-7b-it) | 8.5B | 47.72 GB | gemma | N/A | 1223 | google | transformers, safetensors, gguf |
| [BAGEL-7B-MoT](https://huggingface.co/ByteDance-Seed/BAGEL-7B-MoT) | 14.7B | 27.52 GB | bagel | arxiv:2505.14683 | 1168 | ByteDance-Seed | bagel-mot, safetensors, bagel |
| [chatglm3-6b](https://huggingface.co/zai-org/chatglm3-6b) | 6.2B | 23.26 GB | chatglm | N/A | 1156 | zai-org | transformers, pytorch, safetensors |
| [zephyr-7b-alpha](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha) | 7.2B | 26.98 GB | mistral | N/A | 1116 | HuggingFaceH4 | transformers, pytorch, safetensors |
| [gemma-3-4b-it](https://huggingface.co/google/gemma-3-4b-it) | 4.3B | 8.01 GB | gemma3 | N/A | 1048 | google | transformers, safetensors, gemma3 |
| [DeepSeek-V3.1-Base](https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Base) | 684.5B | 641.3 GB | deepseek_v3 | V3.1 | 1005 | deepseek-ai | transformers, safetensors, deepseek_v3 |
| [DeepSeek-R1-0528-Qwen3-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B) | 8.2B | 15.26 GB | qwen3 | N/A | 1001 | deepseek-ai | transformers, safetensors, qwen3 |
| [Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) | 4.1B | 7.72 GB | phi3_v | N/A | 969 | microsoft | transformers, safetensors, phi3_v |
| [Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct) | 7.6B | 14.19 GB | qwen2 | 2.5 | 955 | Qwen | transformers, safetensors, qwen2 |
| [Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct) | 3.8B | 7.12 GB | phi3 | 3.5 | 938 | microsoft | transformers, safetensors, phi3 |
| [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) | 8.0B | 14.96 GB | llama | N/A | 834 | deepseek-ai | transformers, safetensors, llama |
| [DCLM-7B](https://huggingface.co/apple/DCLM-7B) | 6.9B | 25.67 GB | openlm | N/A | 832 | apple | transformers, safetensors, openlm |
| [gemma-3n-E4B-it](https://huggingface.co/google/gemma-3n-E4B-it) | 7.8B | 14.63 GB | gemma3n | N/A | 831 | google | transformers, safetensors, gemma3n |
| [Qwen3-8B](https://huggingface.co/Qwen/Qwen3-8B) | 8.2B | 15.26 GB | qwen3 | N/A | 814 | Qwen | transformers, safetensors, qwen3 |
| [medgemma-4b-it](https://huggingface.co/google/medgemma-4b-it) | 4.3B | 8.01 GB | gemma3 | N/A | 797 | google | transformers, safetensors, gemma3 |
| [Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat) | 7.7B | 14.38 GB | qwen | N/A | 784 | Qwen | transformers, safetensors, qwen |
| [DeepSeek-R1-Distill-Qwen-7B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B) | 7.6B | 14.19 GB | qwen2 | N/A | 763 | deepseek-ai | transformers, safetensors, qwen2 |
| [Phi-3.5-vision-instruct](https://huggingface.co/microsoft/Phi-3.5-vision-instruct) | 4.1B | 7.72 GB | phi3_v | 3.5 | 720 | microsoft | transformers, safetensors, phi3_v |
| [Hunyuan-MT-7B](https://huggingface.co/tencent/Hunyuan-MT-7B) | 8.0B | 14.96 GB | hunyuan_v1_dense | N/A | 708 | tencent | transformers, safetensors, hunyuan_v1_dense |
| [olmOCR-7B-0225-preview](https://huggingface.co/allenai/olmOCR-7B-0225-preview) | 8.3B | 15.44 GB | qwen2_vl | license:apache-2.0 | 705 | allenai | transformers, safetensors, qwen2_vl |
| [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct) | 7.6B | 14.19 GB | qwen2 | N/A | 679 | Qwen | transformers, safetensors, qwen2 |
| [CogVideoX-5b](https://huggingface.co/zai-org/CogVideoX-5b) | Unknown | Unknown | Unknown | N/A | 657 | zai-org | diffusers, safetensors, cogvideox |
| [OLMo-7B](https://huggingface.co/allenai/OLMo-7B) | 6.9B | 51.32 GB | hf_olmo | N/A | 650 | allenai | transformers, pytorch, safetensors |
| [Phi-4-mini-instruct](https://huggingface.co/microsoft/Phi-4-mini-instruct) | 3.8B | 7.15 GB | phi3 | N/A | 646 | microsoft | transformers, safetensors, phi3 |
| [Llama-2-7b-chat](https://huggingface.co/meta-llama/Llama-2-7b-chat) | Unknown | 12.55 GB | llama | N/A | 613 | meta-llama | facebook, meta, pytorch |
| [Mamba-Codestral-7B-v0.1](https://huggingface.co/mistralai/Mamba-Codestral-7B-v0.1) | 7.3B | 27.14 GB | Unknown | v0.1 | 607 | mistralai | vllm, safetensors, mistral-common |
| [Voxtral-Mini-3B-2507](https://huggingface.co/mistralai/Voxtral-Mini-3B-2507) | 4.7B | 17.42 GB | voxtral | N/A | 599 | mistralai | mistral-common, safetensors, voxtral |
| [Qwen2.5-VL-3B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct) | 3.8B | 6.99 GB | qwen2_5_vl | 2.5 | 577 | Qwen | transformers, safetensors, qwen2_5_vl |
| [Qwen2.5-Coder-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct) | 7.6B | 14.19 GB | qwen2 | 2.5 | 573 | Qwen | transformers, safetensors, qwen2 |
| [Phi-3.5-MoE-instruct](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct) | 41.9B | 78.0 GB | phimoe | 3.5 | 566 | microsoft | transformers, safetensors, phimoe |
| [Ministral-8B-Instruct-2410](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410) | 8.0B | 29.88 GB | mistral | N/A | 564 | mistralai | vllm, safetensors, mistral |
| [Molmo-7B-D-0924](https://huggingface.co/allenai/Molmo-7B-D-0924) | 8.0B | 29.88 GB | molmo | N/A | 558 | allenai | transformers, safetensors, molmo |
| [Llama3-ChatQA-1.5-8B](https://huggingface.co/nvidia/Llama3-ChatQA-1.5-8B) | 8.0B | 14.96 GB | llama | 1.5 | 554 | nvidia | transformers, safetensors, llama |
| [Mistral-7B-v0.3](https://huggingface.co/mistralai/Mistral-7B-v0.3) | 7.2B | 27.0 GB | mistral | v0.3 | 548 | mistralai | vllm, safetensors, mistral |
| [neural-chat-7b-v3-1](https://huggingface.co/Intel/neural-chat-7b-v3-1) | 7.2B | 26.98 GB | mistral | v3 | 547 | Intel | transformers, pytorch, safetensors |
| [LLaMA-2-7B-32K](https://huggingface.co/togethercomputer/LLaMA-2-7B-32K) | Unknown | 12.55 GB | llama | N/A | 538 | togethercomputer | transformers, pytorch, llama |
| [NV-Embed-v2](https://huggingface.co/nvidia/NV-Embed-v2) | 7.9B | 14.62 GB | nvembed | v2 | 490 | nvidia | transformers, safetensors, nvembed |
| [deepseek-coder-6.7b-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct) | 6.7B | 25.11 GB | llama | 6.7 | 461 | deepseek-ai | transformers, pytorch, safetensors |
| [MiniCPM-V-4](https://huggingface.co/openbmb/MiniCPM-V-4) | 4.1B | 7.56 GB | minicpmv | license:apache-2.0 | 460 | openbmb | transformers, safetensors, minicpmv |
| [Nemotron-Orchestrator-8B](https://huggingface.co/nvidia/Nemotron-Orchestrator-8B) | 8.2B | 30.51 GB | qwen3 | N/A | 460 | nvidia | transformers, safetensors, qwen3 |
| [Wan2.2-TI2V-5B](https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B) | 5B | 31.83 GB | ti2v | 2.2 | 458 | Wan-AI | wan2.2, diffusers, safetensors |
| [UI-TARS-1.5-7B](https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B) | 8.3B | 30.89 GB | qwen2_5_vl | 1.5 | 457 | ByteDance-Seed | transformers, safetensors, qwen2_5_vl |
| [Fara-7B](https://huggingface.co/microsoft/Fara-7B) | 8.3B | 15.45 GB | qwen2_5_vl | N/A | 443 | microsoft | transformers, safetensors, qwen2_5_vl |
| [Kimi-VL-A3B-Thinking](https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking) | 16.4B | 30.56 GB | kimi_vl | N/A | 442 | moonshotai | transformers, safetensors, kimi_vl |
| [blip2-opt-2.7b](https://huggingface.co/Salesforce/blip2-opt-2.7b) | 3.7B | 28.38 GB | blip-2 | 2.7 | 425 | Salesforce | transformers, pytorch, safetensors |
| [aya-23-8B](https://huggingface.co/CohereLabs/aya-23-8B) | 8.0B | 14.95 GB | cohere | N/A | 425 | CohereLabs | transformers, safetensors, cohere |
| [chatglm-6b-int4](https://huggingface.co/zai-org/chatglm-6b-int4) | Unknown | 3.63 GB | chatglm | N/A | 418 | zai-org | transformers, pytorch, chatglm |
| [MiniCPM3-4B](https://huggingface.co/openbmb/MiniCPM3-4B) | Unknown | 7.59 GB | minicpm3 | N/A | 416 | openbmb | transformers, pytorch, minicpm3 |
| [aya-expanse-8b](https://huggingface.co/CohereLabs/aya-expanse-8b) | 8.0B | 14.95 GB | cohere | N/A | 415 | CohereLabs | transformers, safetensors, cohere |
| [EXAONE-3.0-7.8B-Instruct](https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct) | 7.8B | 29.13 GB | exaone | 3.0 | 414 | LGAI-EXAONE | transformers, safetensors, exaone |
| [Magma-8B](https://huggingface.co/microsoft/Magma-8B) | 8.9B | 16.58 GB | magma | N/A | 411 | microsoft | transformers, safetensors, magma |
| [c4ai-command-r7b-12-2024](https://huggingface.co/CohereLabs/c4ai-command-r7b-12-2024) | 8.0B | 14.95 GB | cohere2 | N/A | 399 | CohereLabs | transformers, safetensors, cohere2 |
| [Phi-3-medium-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) | 14.0B | 26.0 GB | phi3 | N/A | 385 | microsoft | transformers, safetensors, phi3 |
| [MiniCPM4.1-8B](https://huggingface.co/openbmb/MiniCPM4.1-8B) | 8.2B | 15.25 GB | minicpm | 4.1 | 383 | openbmb | transformers, safetensors, minicpm |
| [Yi-6B](https://huggingface.co/01-ai/Yi-6B) | 6.1B | 22.58 GB | llama | arxiv:2403.04652 | 377 | 01-ai | transformers, pytorch, safetensors |
| [Kimi-Audio-7B-Instruct](https://huggingface.co/moonshotai/Kimi-Audio-7B-Instruct) | 9.8B | 18.19 GB | Unknown | N/A | 375 | moonshotai | kimi-audio, safetensors, audio |
| [stablelm-tuned-alpha-7b](https://huggingface.co/stabilityai/stablelm-tuned-alpha-7b) | Unknown | 29.56 GB | gpt_neox | N/A | 359 | stabilityai | transformers, pytorch, gpt_neox |
| [DeepSeek-R1-0528-Qwen3-8B-GGUF](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF) | Unknown | 128.67 GB | qwen3 | N/A | 343 | unsloth | transformers, gguf, qwen3 |
| [Kimi-VL-A3B-Thinking-2506](https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking-2506) | 16.4B | 30.56 GB | kimi_vl | N/A | 327 | moonshotai | transformers, safetensors, kimi_vl |
| [xgen-7b-8k-base](https://huggingface.co/Salesforce/xgen-7b-8k-base) | Unknown | 25.69 GB | llama | N/A | 317 | Salesforce | transformers, pytorch, llama |
| [aya-vision-8b](https://huggingface.co/CohereLabs/aya-vision-8b) | 8.6B | 16.08 GB | aya_vision | N/A | 316 | CohereLabs | transformers, safetensors, aya_vision |
| [DiffuCoder-7B-cpGRPO](https://huggingface.co/apple/DiffuCoder-7B-cpGRPO) | 7.6B | 14.19 GB | Dream | N/A | 316 | apple | safetensors, Dream, code |
| [dolly-v1-6b](https://huggingface.co/databricks/dolly-v1-6b) | Unknown | 11.38 GB | gptj | v1 | 310 | databricks | transformers, pytorch, gptj |
| [GPT-JT-6B-v1](https://huggingface.co/togethercomputer/GPT-JT-6B-v1) | Unknown | 11.38 GB | gptj | v1 | 302 | togethercomputer | transformers, pytorch, gptj |
| [CogVideoX-5b-I2V](https://huggingface.co/zai-org/CogVideoX-5b-I2V) | Unknown | Unknown | Unknown | N/A | 301 | zai-org | diffusers, safetensors, cogvideox |
| [DeepSeek-R1-Distill-Llama-8B-GGUF](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF) | Unknown | 140.49 GB | llama | N/A | 293 | unsloth | transformers, gguf, llama |
| [chatglm2-6b-32k](https://huggingface.co/zai-org/chatglm2-6b-32k) | 6B | 11.63 GB | chatglm | arxiv:2103.10360 | 293 | zai-org | transformers, pytorch, chatglm |
| [Seed-X-PPO-7B](https://huggingface.co/ByteDance-Seed/Seed-X-PPO-7B) | Unknown | 14.0 GB | mistral | N/A | 285 | ByteDance-Seed | safetensors, mistral, translation |
| [Kimi-K2-Base](https://huggingface.co/moonshotai/Kimi-K2-Base) | 1026.5B | 958.51 GB | kimi_k2 | N/A | 282 | moonshotai | transformers, safetensors, kimi_k2 |
| [MiniCPM4-8B](https://huggingface.co/openbmb/MiniCPM4-8B) | 8.2B | 15.25 GB | minicpm | N/A | 280 | openbmb | transformers, safetensors, minicpm |
| [LFM2-8B-A1B](https://huggingface.co/LiquidAI/LFM2-8B-A1B) | 8.3B | 46.6 GB | lfm2_moe | N/A | 272 | LiquidAI | transformers, safetensors, lfm2_moe |
| [MiMo-7B-RL](https://huggingface.co/XiaomiMiMo/MiMo-7B-RL) | 7.8B | 14.59 GB | mimo | N/A | 268 | XiaomiMiMo | transformers, safetensors, mimo |
| [FastVLM-7B](https://huggingface.co/apple/FastVLM-7B) | 7.8B | 14.46 GB | llava_qwen2 | N/A | 262 | apple | ml-fastvlm, safetensors, llava_qwen2 |
| [codegeex2-6b](https://huggingface.co/zai-org/codegeex2-6b) | Unknown | 11.63 GB | chatglm | N/A | 257 | zai-org | transformers, pytorch, chatglm |
| [c4ai-command-r-plus-4bit](https://huggingface.co/CohereLabs/c4ai-command-r-plus-4bit) | 105.4B | 58.6 GB | cohere | N/A | 256 | CohereLabs | transformers, safetensors, cohere |
| [Meta-Llama-3.1-8B-Instruct-GGUF](https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF) | 8B | 32.19 GB | llama | 3.1 | 253 | lmstudio-community | gguf, facebook, meta |
| [CogView4-6B](https://huggingface.co/zai-org/CogView4-6B) | Unknown | Unknown | Unknown | N/A | 248 | zai-org | diffusers, safetensors, text-to-image |
| [chatglm3-6b-32k](https://huggingface.co/zai-org/chatglm3-6b-32k) | Unknown | 11.63 GB | chatglm | N/A | 246 | zai-org | transformers, pytorch, chatglm |
| [Kimi-VL-A3B-Instruct](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct) | 16.4B | 30.56 GB | kimi_vl | N/A | 244 | moonshotai | transformers, safetensors, kimi_vl |
| [chatglm2-6b-int4](https://huggingface.co/zai-org/chatglm2-6b-int4) | Unknown | 3.66 GB | chatglm | N/A | 238 | zai-org | transformers, pytorch, chatglm |
| [Cosmos-1.0-Diffusion-7B-Text2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Text2World) | Unknown | 13.48 GB | Unknown | 1.0 | 229 | nvidia | cosmos, diffusers, safetensors |
| [internlm3-8b-instruct](https://huggingface.co/internlm/internlm3-8b-instruct) | 8.8B | 16.4 GB | internlm3 | N/A | 228 | internlm | safetensors, internlm3, text-generation |
| [Mistral-7B-v0.2](https://huggingface.co/mistral-community/Mistral-7B-v0.2) | 7.2B | 13.49 GB | mistral | v0.2 | 228 | mistral-community | transformers, safetensors, mistral |
