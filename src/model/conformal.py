import torch
import numpy as np
from collections import defaultdict

class JointMondrianConformalPredictor:
    """
    Joint Mondrian Conformal Predictor (Dissertation Chapter 7/8).

    Provides mathematically-guaranteed confidence intervals for both:
    1. On-Target Efficiency (Regression)
    2. Off-Target Risk (Probability/Regression)

    Taxonomy:
    - Uses Epigenetic Context (Mondrian Groups) to ensure local validity.
    - Guarantees 1-alpha coverage per group.
    - Enhanced with Ensemble-based Epistemic Uncertainty.
    """
    def __init__(self, models, alpha=0.1):
        """
        models: List of trained CRISPRO_Apex models (the ensemble).
        alpha: Target error rate (e.g., 0.1 for 90% confidence).
        """
        self.models = models if isinstance(models, list) else [models]
        for m in self.models:
            m.eval()
        self.alpha = alpha

        # Calibration thresholds per group
        self.on_target_qs = {}
        self.off_target_qs = {}

        # Raw scores for calibration
        self.on_target_scores = defaultdict(list)
        self.off_target_scores = defaultdict(list)

    def _get_group(self, epi_tensor):
        """
        Mondrian Taxonomy: Grouping by dominant epigenetic feature.
        """
        if epi_tensor.dim() == 2:
            mean_sig = torch.mean(epi_tensor, dim=0)
        else:
            mean_sig = epi_tensor

        indices = torch.nonzero(mean_sig > 0.5).flatten()
        if len(indices) > 0:
            return int(indices[0].item())
        return -1

    def calibrate(self, dataloader, device="cpu"):
        """
        Strategic Calibration Phase.
        dataloader: Calibration set (held-out from training).
        """
        print(f"üèõÔ∏è Calibrating Joint Conformal Engine (Alpha={self.alpha})...")
        self.on_target_scores.clear()
        self.off_target_scores.clear()

        with torch.no_grad():
            for batch in dataloader:
                dna = batch['dna'].to(device)
                epi = batch['epigenetics'].to(device)
                y_on = batch['on_target'].to(device)
                y_off = batch['off_target'].to(device)

                # 1. Compute Ensemble Mean & Epistemic Uncertainty
                all_preds_on = []
                all_preds_off = []
                for m in self.models:
                    out = m(dna, epi)
                    all_preds_on.append(out['on_target'])
                    all_preds_off.append(out['off_target'])

                # (E, B, 1)
                all_preds_on = torch.stack(all_preds_on)
                all_preds_off = torch.stack(all_preds_off)

                mean_on = all_preds_on.mean(dim=0).squeeze(-1)
                mean_off = all_preds_off.mean(dim=0).squeeze(-1)

                # Epistemic variance (normalized)
                epistemic_on = all_preds_on.var(dim=0).squeeze(-1)
                epistemic_off = all_preds_off.var(dim=0).squeeze(-1)

                # 2. Compute non-conformity scores (S = |y - pred| + Epistemic Penalty)
                # This alignment ensures the interval accounts for both data noise and model disagreement.
                on_scores = torch.abs(y_on - mean_on) + epistemic_on
                off_scores = torch.abs(y_off - mean_off) + epistemic_off

                for i in range(len(on_scores)):
                    group_id = self._get_group(epi[i])
                    self.on_target_scores[group_id].append(on_scores[i].item())
                    self.off_target_scores[group_id].append(off_scores[i].item())

        # Compute Quantiles per group
        for gid in set(list(self.on_target_scores.keys()) + list(self.off_target_scores.keys())):
            # On-Target
            scores = self.on_target_scores[gid]
            if scores:
                n = len(scores)
                q_level = np.ceil((n + 1) * (1 - self.alpha)) / n
                self.on_target_qs[gid] = np.quantile(scores, min(q_level, 1.0), method='higher')

            # Off-Target
            scores = self.off_target_scores[gid]
            if scores:
                n = len(scores)
                q_level = np.ceil((n + 1) * (1 - self.alpha)) / n
                self.off_target_qs[gid] = np.quantile(scores, min(q_level, 1.0), method='higher')

        print(f"‚úÖ Calibration Successful. Optimized {len(self.on_target_qs)} Mondrian Groups.")

    def predict(self, dna, epi):
        """
        Inference with Stratified Bounds.
        Returns: Dict containing preds and [lower, upper] intervals.
        """
        with torch.no_grad():
            outputs = []
            for m in self.models:
                outputs.append(m(dna, epi))

            # Mean Predictions
            on_target = torch.stack([o['on_target'] for o in outputs]).mean(dim=0)
            off_target = torch.stack([o['off_target'] for o in outputs]).mean(dim=0)

            on_bounds = []
            off_bounds = []

            for i in range(dna.shape[0]):
                gid = self._get_group(epi[i])

                # Retrieve calibrated thresholds (fallback to 0.1 if unseen)
                q_on = self.on_target_qs.get(gid, 0.1)
                q_off = self.off_target_qs.get(gid, 0.1)

                on_bounds.append([on_target[i].item() - q_on, on_target[i].item() + q_on])
                off_bounds.append([off_target[i].item() - q_off, off_target[i].item() + q_off])

        return {
            'on_target': on_target,
            'on_target_bounds': torch.tensor(on_bounds),
            'off_target': off_target,
            'off_target_bounds': torch.tensor(off_bounds)
        }

if __name__ == "__main__":
    from src.model.crispro_apex import CRISPRO_Apex

    print("üß¨ Testing Joint Conformal Predictor (Ensemble Enhanced)...")
    # Simulate an ensemble of 2 models
    models = [CRISPRO_Apex(d_model=128, n_layers=1), CRISPRO_Apex(d_model=128, n_layers=1)]
    cp = JointMondrianConformalPredictor(models, alpha=0.1)

    # Mock Data
    dna = torch.randint(0, 5, (2, 256))
    epi = torch.randn(2, 256, 5)

    # Test Prediction
    out = cp.predict(dna, epi)
    print(f"[*] On-Target Point: {out['on_target'][0].item():.4f}")
    print(f"[*] On-Target Bounds: {out['on_target_bounds'][0].tolist()}")
    print(f"[*] Off-Target Bounds: {out['off_target_bounds'][0].tolist()}")
    print("‚úÖ Conformal Architecture Verified.")
